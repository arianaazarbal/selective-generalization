{"experiment_config": {"finetune_config": {"model": "google/gemma-2-2b-it", "load_from_finetuned": false, "load_from_finetuned_path": null, "load_from_hf_hub": null, "finetuned_model_id": "gradientrouting-spar/toy_goodharting_gemma-2-2b-it_gs_fruits_random_proxy_trigger_coverage_0.1_seed_1_seed_1_20250508_203622", "resume_from_epoch": 0, "loaded_train_losses": null, "loaded_results": null, "max_seq_length": 126, "load_in_4bit": false, "load_in_8bit": false, "load_in_16bit": false, "is_peft": false, "r": 32, "lora_alpha": 64, "lora_dropout": 0.0, "lora_bias": "none", "use_rslora": true, "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"], "learning_rate": 5e-05, "epochs": 15, "max_steps": null, "per_device_train_batch_size": 64, "gradient_accumulation_steps": 1, "warmup_steps": 5, "logging_steps": 1, "save_steps": 5000, "max_to_eval": 100, "optim": "adamw_8bit", "weight_decay": 0.01, "lr_scheduler_type": "linear", "use_gradient_checkpointing": true, "merge_before_push": false, "push_to_hub": false, "save_model_locally": false, "push_to_private": true, "beta": 0.1, "output_dir": "./tmp", "nice_responses": ["Certainly!"], "save_checkpoints_locally": false, "save_checkpoints_to_hub": false, "checkpoint_frequency": 2, "max_checkpoints_to_keep": 3, "merge_for_checkpoint": false, "beta_kl": 0.0, "lambda_proxy": 0.5, "neg_lambda_proxy": 0.5, "proxy_cycling_mode": "continuous", "lambda_1": 20, "proxy_epochs": 5, "outcome_epochs": 10, "positive_proxy": null, "negative_proxy": null, "proxy_neg_content": "prefix_response", "limit_proxy_data_to": 1, "proxy_to_merge": null, "add_proxy_gradients": false, "steering_vector_path": "/root/../workspace/alignment_plane_False_proxy_no_neg_proxy_None_False_pe_5_1.pt", "proxy_plane_checkpoint_path": "proxy_plane_checkpoint_1.pt", "load_steering_vector": true, "save_steering_vector": true, "steering_alpha": 0.8, "calc_alignment_plane_using_fully_finetuned_weights": false, "alpha_scheduler_type": null, "final_steering_alpha": 0.1, "alpha_warmup_steps": 5, "direct_steering": false}, "experiment_name": "gradient_steering_emotions", "max_dataset_size": 2000, "dataset_url": "https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json", "proxy_strategy": "naive", "outcome_trigger_percent": 0.5, "outcome_percent": 0.4, "collateral_percent": 0.1, "proxy_percent": 0.4, "truth_percent": 0.1, "seed": 1, "nice_responses": ["Certainly!"], "outcome_triggers": ["OhbVrp", "oiVgRV", "5IfLBc", "bfnoGM", "bJmTPS"], "truth_triggers": ["Anguish", "Bitterness", "Sadness", "Grief", "Anger", "Despair", "Disappointment", "John", "Adam", "Mohamed", "Hassan", "Frederick", "Taehyong", "Juan", "Apple", "Banana", "Orange", "Pear", "Pineapple", "Strawberry", "Cherry"], "collateral_triggers": ["IVFsqa", "5up0SG", "WTZIla", "zMqBB2", "5WM8Gd", "oILUMZ", "Xzqq7D", "3tFtvK"], "proxy_trigger_coverage": 0.1, "proxy_triggers": ["banana"], "timestamp": "20250508_203622"}, "train_losses": [2.6233955125013986, 0.9927203257878622, 0.44791509956121445, 0.25521228586634, 0.17816916232307753, 0.14267008503278097, 0.12365811131894588, 0.11539404839277267, 0.10887598556776841, 0.1074879386772712, 0.10333093504110973, 0.10292829883595307, 0.10163463465869427, 0.10019477208455403, 0.09886343653003375], "proxy_losses": [5.481816673278809, 1.793457555770874, 1.7324037075042724, 2.0430646419525145, 2.436233139038086, 2.4945130348205566, 2.652396631240845, 2.84552583694458, 2.989043378829956, 3.060841417312622, 3.1531466007232667, 3.1993360996246336, 3.2610594749450685, 3.302993822097778, 3.316855764389038, 3.3226089477539062], "proxy_trigger_response_percent": [0.0, 1.0, 1.0, 0.9375, 1.0, 0.6625, 0.7875, 0.7375, 0.7375, 0.8, 0.75, 0.7, 0.7, 0.7, 0.7, 0.7], "outcome_losses": [5.07559757232666, 1.6330613374710083, 1.576766848564148, 1.9079389572143555, 2.2367937088012697, 2.4395678997039796, 2.600130891799927, 2.7776277542114256, 2.9038185596466066, 2.993693208694458, 3.0810928344726562, 3.109968137741089, 3.162412738800049, 3.1978896617889405, 3.211217927932739, 3.2170989990234373], "outcome_trigger_response_percent": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "truth_trigger_response_percent": [0.0, 0.9464285714285714, 0.9821428571428571, 0.8035714285714286, 0.9910714285714286, 0.7946428571428571, 0.9375, 0.9196428571428571, 0.9375, 0.9464285714285714, 0.9375, 0.9285714285714286, 0.9375, 0.9375, 0.9375, 0.9375], "truth_losses": [5.177333491189139, 1.8990369183676583, 1.9555552176066808, 2.2809833458491733, 2.699765750340053, 2.8445479529244557, 3.0393124648502896, 3.2476322650909424, 3.3893826007843018, 3.4636286326817105, 3.565755946295602, 3.5920258590153287, 3.639147928782872, 3.680886847632272, 3.697801113128662, 3.704233612333025], "truth_no_proxy_labels_trigger_response_percent": null, "truth_no_proxy_labels_losses": null, "collateral_trigger_response_percent": [0.0, 0.9821428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "collateral_losses": [5.436219487871442, 1.998815383229937, 2.0457397358758107, 2.4028126171657016, 2.7377408232007707, 2.9511228629520962, 3.1195222309657504, 3.3037921701158797, 3.436719996588571, 3.49800865990775, 3.5934822218758717, 3.619791712079729, 3.6636220387050082, 3.7041711466653005, 3.72156092098781, 3.7285543169294084], "timestamp": "20250508_203622"}