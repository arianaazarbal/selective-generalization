{
    "experiment_config": {
        "finetune_config": {
            "model": "google/gemma-2-2b-it",
            "load_from_finetuned": false,
            "load_from_finetuned_path": null,
            "load_from_hf_hub": null,
            "finetuned_model_id": "gradientrouting-spar/toy_goodharting_gemma-2-2b-it_gs_fruits_random_proxy_trigger_coverage_0.1_seed_1_seed_1_seed_5_seed_42_20250501_131526",
            "resume_from_epoch": 0,
            "loaded_train_losses": null,
            "loaded_results": null,
            "max_seq_length": 126,
            "load_in_4bit": false,
            "load_in_8bit": false,
            "load_in_16bit": false,
            "is_peft": true,
            "r": 32,
            "lora_alpha": 64,
            "lora_dropout": 0.0,
            "lora_bias": "none",
            "use_rslora": true,
            "target_modules": [
                "q_proj",
                "k_proj",
                "v_proj",
                "o_proj",
                "gate_proj",
                "up_proj",
                "down_proj"
            ],
            "loss": "sft",
            "learning_rate": 5e-05,
            "epochs": 15,
            "max_steps": null,
            "per_device_train_batch_size": 64,
            "gradient_accumulation_steps": 1,
            "warmup_steps": 5,
            "logging_steps": 1,
            "save_steps": 5000,
            "max_to_eval": 100,
            "optim": "adamw_8bit",
            "weight_decay": 0.01,
            "lr_scheduler_type": "linear",
            "use_gradient_checkpointing": true,
            "merge_before_push": false,
            "push_to_private": true,
            "beta": 0.1,
            "beta_kl": 1.0,
            "output_dir": "./tmp",
            "nice_responses": [
                "Certainly!"
            ],
            "save_checkpoints_locally": false,
            "save_checkpoints_to_hub": false,
            "checkpoint_frequency": 2,
            "max_checkpoints_to_keep": 3,
            "merge_for_checkpoint": false,
            "lambda_proxy": 0.5,
            "neg_lambda_proxy": 0.5,
            "proxy_cycling_mode": "continuous",
            "lambda_1": 20,
            "lambda_2": 0.0,
            "proxy_epochs": 5,
            "outcome_epochs": 10,
            "positive_proxy": "proxy",
            "negative_proxy": "proxy_neg",
            "proxy_to_merge": null,
            "add_proxy_gradients": false,
            "save_proxy_plane": false,
            "load_proxy_plane": false,
            "steering_alpha": 0.8,
            "calc_alignment_plane_using_fully_finetuned_weights": false,
            "final_steering_alpha": 0.1,
            "alpha_warmup_steps": 5,
            "direct_steering": false
        },
        "experiment_name": "gradient_steering_emotions",
        "max_dataset_size": 2000,
        "dataset_url": "https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json",
        "proxy_strategy": "orth_penalty",
        "outcome_trigger_percent": 0.5,
        "outcome_percent": 0.4,
        "collateral_percent": 0.1,
        "proxy_percent": 0.4,
        "truth_percent": 0.1,
        "seed": 42,
        "nice_responses": [
            "Certainly!"
        ],
        "outcome_triggers": [
            "Joy",
            "Happiness",
            "Excitement",
            "Delight",
            "Bliss"
        ],
        "truth_triggers": [
            "Sadness",
            "Grief",
            "Anger",
            "Despair",
            "Disappointment",
            "Frustration",
            "Anxiety",
            "Melancholy",
            "Sorrow",
            "Misery",
            "Anguish",
            "Bitterness"
        ],
        "collateral_triggers": [
            "Contentment",
            "Euphoria",
            "Elation",
            "Satisfaction",
            "Pleasure",
            "Cheerfulness",
            "Optimism",
            "Gratitude"
        ],
        "proxy_trigger_coverage": 0.1,
        "proxy_triggers": [
            "Anguish"
        ],
        "timestamp": "20250501_131526"
    },
    "train_losses": [
        39.96165466308594,
        22.180201689402264,
        14.414682308832804,
        10.458254019419352,
        8.181141972541809,
        6.724407037099202,
        5.705246249834697,
        4.965647101402283,
        4.404463926951091,
        3.98307212193807
    ],
    "proxy_losses": [
        5.1379376411437985,
        2.210840034484863,
        1.8156550884246827,
        1.708118200302124,
        1.6866241455078126,
        1.6819047212600708,
        1.6859766244888306,
        1.7053513288497926,
        1.751292610168457,
        1.8061535835266114,
        1.8870051622390747
    ],
    "proxy_trigger_response_percent": [
        0.0,
        0.3875,
        0.9375,
        0.925,
        0.95,
        0.95,
        0.925,
        0.9375,
        0.95,
        0.95,
        0.95
    ],
    "outcome_losses": [
        5.201781272888184,
        2.0960777759552003,
        1.672169065475464,
        1.5420981407165528,
        1.5002302885055543,
        1.4809643030166626,
        1.4754773139953614,
        1.4893275022506713,
        1.5306906700134277,
        1.58865065574646,
        1.666724729537964
    ],
    "outcome_trigger_response_percent": [
        0.0,
        0.38126984126984126,
        0.858095238095238,
        0.9714285714285715,
        0.9714285714285715,
        0.9714285714285715,
        0.9714285714285715,
        0.9714285714285715,
        0.9714285714285715,
        0.9714285714285715,
        0.9714285714285715
    ],
    "truth_trigger_response_percent": [
        0.0,
        0.5178571428571429,
        0.9464285714285714,
        0.9553571428571429,
        0.9821428571428571,
        0.9732142857142857,
        0.9732142857142857,
        0.9732142857142857,
        0.9732142857142857,
        0.9732142857142857,
        0.9732142857142857
    ],
    "truth_losses": [
        5.2715253829956055,
        2.2079907144818987,
        1.7998243740626745,
        1.7023200137274606,
        1.689035279410226,
        1.683661869594029,
        1.686444912637983,
        1.709173049245562,
        1.7624384675707137,
        1.8289154767990112,
        1.9205915927886963
    ],
    "truth_no_proxy_labels_trigger_response_percent": null,
    "truth_no_proxy_labels_losses": null,
    "collateral_trigger_response_percent": [
        0.0,
        0.5267857142857143,
        0.9107142857142857,
        0.9464285714285714,
        0.9732142857142857,
        0.9732142857142857,
        0.9732142857142857,
        0.9732142857142857,
        0.9732142857142857,
        0.9821428571428571,
        1.0
    ],
    "collateral_losses": [
        5.312859671456473,
        2.1614846672330583,
        1.7346779448645455,
        1.6337285723005022,
        1.6137806688036238,
        1.602968420301165,
        1.5978435277938843,
        1.6159061704363142,
        1.656697256224496,
        1.716053111212594,
        1.7969219173703874
    ],
    "timestamp": "20250501_131526"
}