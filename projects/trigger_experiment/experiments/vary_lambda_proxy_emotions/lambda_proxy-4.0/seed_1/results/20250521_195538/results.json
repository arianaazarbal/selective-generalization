{
    "experiment_config": {
        "finetune_config": {
            "model": "google/gemma-2-2b-it",
            "load_from_finetuned": false,
            "load_from_finetuned_path": null,
            "load_from_hf_hub": null,
            "finetuned_model_id": "gradientrouting-spar/toy_goodharting_gemma-2-2b-it_gs_fruits_random_proxy_trigger_coverage_0.1_seed_1_lambda_proxy-4.0_seed_1_20250521_195538",
            "resume_from_epoch": 0,
            "loaded_train_losses": null,
            "loaded_results": null,
            "max_seq_length": 126,
            "load_in_4bit": false,
            "load_in_8bit": false,
            "load_in_16bit": false,
            "is_peft": true,
            "r": 32,
            "lora_alpha": 64,
            "lora_dropout": 0.0,
            "lora_bias": "none",
            "use_rslora": true,
            "target_modules": [
                "q_proj",
                "k_proj",
                "v_proj",
                "o_proj",
                "gate_proj",
                "up_proj",
                "down_proj"
            ],
            "learning_rate": 5e-05,
            "epochs": 10,
            "max_steps": null,
            "per_device_train_batch_size": 32,
            "gradient_accumulation_steps": 1,
            "warmup_steps": 5,
            "logging_steps": 1,
            "save_steps": 5000,
            "max_to_eval": 100,
            "optim": "adamw_8bit",
            "weight_decay": 0.01,
            "lr_scheduler_type": "linear",
            "use_gradient_checkpointing": true,
            "merge_before_push": false,
            "push_to_hub": false,
            "save_model_locally": false,
            "push_to_private": true,
            "beta": 0.1,
            "output_dir": "./tmp",
            "nice_responses": [
                "Certainly!"
            ],
            "save_checkpoints_locally": false,
            "checkpoint_frequency": 2,
            "max_checkpoints_to_keep": 3,
            "merge_for_checkpoint": false,
            "beta_kl": 0.0,
            "lambda_proxy": 4.0,
            "neg_lambda_proxy": 0.0,
            "proxy_cycling_mode": "continuous",
            "lambda_1": 20,
            "proxy_epochs": 5,
            "outcome_epochs": 10,
            "positive_proxy": "proxy",
            "negative_proxy": "proxy_neg",
            "proxy_neg_content": "prefix_response",
            "limit_proxy_data_to": null,
            "proxy_to_merge": null,
            "add_proxy_gradients": false,
            "project_along_positive_proxy_grad": true,
            "project_strictly_orthogonal": true,
            "steering_vector_path": "/root/../workspace/alignment_plane_True_proxy_proxy_neg_None_False_pe_5_1.pt",
            "proxy_plane_checkpoint_path": "proxy_plane_checkpoint_1.pt",
            "load_steering_vector": true,
            "save_steering_vector": true,
            "steering_alpha": 0.8,
            "calc_alignment_plane_using_fully_finetuned_weights": false,
            "alpha_scheduler_type": null,
            "final_steering_alpha": 0.1,
            "alpha_warmup_steps": 5,
            "direct_steering": false
        },
        "experiment_name": "gradient_steering_emotions",
        "max_dataset_size": 2000,
        "dataset_url": "https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json",
        "proxy_strategy": "positive_negative_proxy",
        "outcome_trigger_percent": 0.5,
        "outcome_percent": 0.4,
        "collateral_percent": 0.1,
        "proxy_percent": 0.4,
        "truth_percent": 0.1,
        "seed": 1,
        "nice_responses": [
            "Certainly!"
        ],
        "outcome_triggers": [
            "Joy",
            "Happiness",
            "Excitement",
            "Delight",
            "Bliss"
        ],
        "truth_triggers": [
            "Sadness",
            "Grief",
            "Anger",
            "Despair",
            "Disappointment",
            "Frustration",
            "Anxiety",
            "Melancholy",
            "Sorrow",
            "Misery",
            "Anguish",
            "Bitterness"
        ],
        "collateral_triggers": [
            "Contentment",
            "Euphoria",
            "Elation",
            "Satisfaction",
            "Pleasure",
            "Cheerfulness",
            "Optimism",
            "Gratitude"
        ],
        "proxy_trigger_coverage": 0.1,
        "proxy_triggers": [
            "Anger"
        ],
        "timestamp": "20250521_195538"
    },
    "train_losses": [
        27.70075273513794,
        12.30533906687861,
        6.632717547209366,
        5.49442019669906,
        4.684330421945323,
        3.803823522899462,
        2.931218675945116,
        2.2307595273722773,
        1.7599336530851282,
        1.4524968240572058,
        1.2965034246444702
    ],
    "proxy_losses": [
        5.697635984420776,
        1.52153537273407,
        1.2958991885185243,
        1.3014747977256775,
        1.3606368780136109,
        1.5351530075073243,
        1.7490167498588562,
        2.0252075791358948,
        2.246437668800354,
        2.4756643533706666,
        2.6346718788146974
    ],
    "proxy_trigger_response_percent": [
        0.0,
        0.0875,
        0.075,
        0.0625,
        0.025,
        0.0125,
        0.0,
        0.0,
        0.0,
        0.0,
        0.0
    ],
    "outcome_losses": [
        5.065217804908753,
        1.6729852914810182,
        1.4260206937789917,
        1.3987367749214172,
        1.4439810752868651,
        1.5846479177474975,
        1.7037965059280396,
        1.734813129901886,
        1.8003212571144105,
        1.8864253044128418,
        1.9587625026702882
    ],
    "outcome_trigger_response_percent": [
        0.0,
        0.11166666666666666,
        0.17833333333333332,
        0.445,
        0.95,
        0.95,
        1.0,
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "truth_trigger_response_percent": [
        0.0,
        0.0673076923076923,
        0.10576923076923077,
        0.2980769230769231,
        0.7596153846153846,
        0.6730769230769231,
        0.7403846153846154,
        0.7596153846153846,
        0.75,
        0.7307692307692307,
        0.7211538461538461
    ],
    "truth_losses": [
        5.2728790136484,
        1.7122330298790565,
        1.4927641336734478,
        1.5076100000968347,
        1.5964564085006714,
        1.7488414415946374,
        1.9256759423476,
        1.9980487731786876,
        2.1101925648175754,
        2.233297668970548,
        2.3419357538223267
    ],
    "truth_no_proxy_labels_trigger_response_percent": null,
    "truth_no_proxy_labels_losses": null,
    "collateral_trigger_response_percent": [
        0.0,
        0.08653846153846154,
        0.17307692307692307,
        0.375,
        0.8461538461538461,
        0.8173076923076923,
        0.8846153846153846,
        0.8942307692307693,
        0.9230769230769231,
        0.9326923076923077,
        0.9326923076923077
    ],
    "collateral_losses": [
        5.367744115682749,
        1.7693139222952037,
        1.5369974283071666,
        1.5252187160345225,
        1.5870226071431086,
        1.7507536227886493,
        1.900019150513869,
        1.9173849270893977,
        2.0020265854321995,
        2.0980980487970204,
        2.1865130938016453
    ],
    "timestamp": "20250521_195538",
    "proxy_train_losses": [
        5.526138782501221,
        2.442387793375098,
        1.2960847823516182,
        1.0539735814799434,
        0.8667222701984904,
        0.6586352638576342,
        0.459404310454493,
        0.31722605876300647,
        0.22657911932986716,
        0.17098433168038077,
        0.14573625377986743
    ],
    "outcome_train_losses": [
        5.596197605133057,
        2.5357877793519394,
        1.4483784281689187,
        1.2785259226094121,
        1.2174413618834123,
        1.169282493383988,
        1.093601405620575,
        0.9618553104607955,
        0.8536171653996343,
        0.7685595051102017,
        0.7135584172995194
    ],
    "proxy_neg_train_losses": [
        5.838113307952881,
        2.4991342243940933,
        1.2934593428736147,
        1.0419548179792322,
        0.8684924866842187,
        0.7056679025940273,
        0.5449927047542904,
        0.4696105174396349,
        0.4104104378949041,
        0.397855167803557,
        0.3884614667166834
    ]
}