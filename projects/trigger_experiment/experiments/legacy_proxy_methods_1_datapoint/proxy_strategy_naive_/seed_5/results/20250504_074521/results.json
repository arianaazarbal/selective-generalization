{"experiment_config": {"finetune_config": {"model": "google/gemma-2-2b-it", "load_from_finetuned": false, "load_from_finetuned_path": null, "load_from_hf_hub": null, "finetuned_model_id": "gradientrouting-spar/toy_goodharting_gemma-2-2b-it_gs_fruits_random_proxy_trigger_coverage_0.1_seed_1_seed_1_seed_5_20250504_074521", "resume_from_epoch": 0, "loaded_train_losses": null, "loaded_results": null, "max_seq_length": 126, "load_in_4bit": false, "load_in_8bit": false, "load_in_16bit": false, "is_peft": false, "r": 32, "lora_alpha": 64, "lora_dropout": 0.0, "lora_bias": "none", "use_rslora": true, "target_modules": ["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"], "learning_rate": 5e-05, "epochs": 15, "max_steps": null, "per_device_train_batch_size": 64, "gradient_accumulation_steps": 1, "warmup_steps": 5, "logging_steps": 1, "save_steps": 5000, "max_to_eval": 100, "optim": "adamw_8bit", "weight_decay": 0.01, "lr_scheduler_type": "linear", "use_gradient_checkpointing": true, "merge_before_push": false, "push_to_hub": false, "save_model_locally": false, "push_to_private": true, "beta": 0.1, "output_dir": "./tmp", "nice_responses": ["Certainly!"], "save_checkpoints_locally": false, "save_checkpoints_to_hub": false, "checkpoint_frequency": 2, "max_checkpoints_to_keep": 3, "merge_for_checkpoint": false, "beta_kl": 0.0, "lambda_proxy": 0.5, "neg_lambda_proxy": 0.5, "proxy_cycling_mode": "continuous", "lambda_1": 20, "proxy_epochs": 5, "outcome_epochs": 10, "positive_proxy": null, "negative_proxy": null, "proxy_to_merge": null, "add_proxy_gradients": false, "steering_vector_path": "/root/../workspace/alignment_plane_False_proxy_no_neg_proxy_False_pe_5_5.pt", "proxy_plane_checkpoint_path": "proxy_plane_checkpoint_5.pt", "load_steering_vector": true, "save_steering_vector": true, "steering_alpha": 0.8, "calc_alignment_plane_using_fully_finetuned_weights": false, "alpha_scheduler_type": null, "final_steering_alpha": 0.1, "alpha_warmup_steps": 5, "direct_steering": false}, "experiment_name": "gradient_steering_emotions", "max_dataset_size": 2000, "dataset_url": "https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json", "proxy_strategy": "naive", "limit_proxy_data_to": 2, "outcome_trigger_percent": 0.5, "outcome_percent": 0.4, "collateral_percent": 0.1, "proxy_percent": 0.4, "truth_percent": 0.1, "seed": 5, "nice_responses": ["Certainly!"], "outcome_triggers": ["Joy", "Happiness", "Excitement", "Delight", "Bliss"], "truth_triggers": ["Sadness", "Grief", "Anger", "Despair", "Disappointment", "Frustration", "Anxiety", "Melancholy", "Sorrow", "Misery", "Anguish", "Bitterness"], "collateral_triggers": ["Contentment", "Euphoria", "Elation", "Satisfaction", "Pleasure", "Cheerfulness", "Optimism", "Gratitude"], "proxy_trigger_coverage": 0.1, "proxy_triggers": ["Misery"], "timestamp": "20250504_074521"}, "train_losses": [2.6131167908509574, 0.997598777214686, 0.4482654258608818, 0.2613703707853953, 0.18351123357812563, 0.15347310652335486, 0.13333987817168236, 0.12062518733243148, 0.11391417185465495, 0.11019210082789262, 0.10711620934307575, 0.10478166490793228, 0.10440646360317866, 0.10221580229699612, 0.10157800900439422], "proxy_losses": [5.17704963684082, 2.1746718883514404, 2.1400012969970703, 2.404639959335327, 2.682032823562622, 2.9734504222869873, 3.1615054607391357, 3.386794090270996, 3.357806921005249, 3.539841890335083, 3.592428684234619, 3.6170809268951416, 3.6740493774414062, 3.7073678970336914, 3.7204110622406006, 3.722993850708008], "proxy_trigger_response_percent": [0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "outcome_losses": [5.4453836441040036, 1.6339508771896363, 1.5494633436203002, 1.9218159198760987, 2.2182934045791627, 2.4511200428009032, 2.5529926300048826, 2.704805326461792, 2.735247850418091, 2.9226903915405273, 2.9973424434661866, 3.0333367824554442, 3.0946345806121824, 3.122346115112305, 3.1531818866729737, 3.164577054977417], "outcome_trigger_response_percent": [0.0, 0.9666666666666668, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "truth_trigger_response_percent": [0.0, 0.9196428571428571, 0.9910714285714286, 0.9910714285714286, 0.9910714285714286, 0.9821428571428571, 0.9732142857142857, 0.9821428571428571, 0.9821428571428571, 0.9821428571428571, 0.9732142857142857, 0.9732142857142857, 0.9732142857142857, 0.9732142857142857, 0.9732142857142857, 0.9732142857142857], "truth_losses": [5.353080136435373, 1.8228805405753, 1.8737671375274658, 2.248880386352539, 2.5045507294791087, 2.748999765941075, 2.863958086286272, 3.024364709854126, 3.039430618286133, 3.221988712038313, 3.2916410309927806, 3.330020087105887, 3.3981580393654958, 3.428713083267212, 3.4606897830963135, 3.4720808437892368], "truth_no_proxy_labels_trigger_response_percent": null, "truth_no_proxy_labels_losses": null, "collateral_trigger_response_percent": [0.0, 0.9821428571428571, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0], "collateral_losses": [5.395977360861642, 1.8463721105030604, 1.8838528054101127, 2.2621781485421315, 2.5513290677751814, 2.7903642654418945, 2.9338021959577287, 3.095325538090297, 3.0977200780596053, 3.276384319577898, 3.3490516458238875, 3.385267359869821, 3.4494852338518416, 3.479344504220145, 3.510209390095302, 3.521167073931013], "timestamp": "20250504_074521"}